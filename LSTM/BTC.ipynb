{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T18:20:13.312456Z",
     "start_time": "2025-03-22T18:20:04.479545Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:20:13.348862Z",
     "start_time": "2025-03-22T18:20:13.331454Z"
    }
   },
   "cell_type": "code",
   "source": "import data.data_retriever as data_retriever",
   "id": "5dcf505a2204266c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:20:13.391665Z",
     "start_time": "2025-03-22T18:20:13.366376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(0)"
   ],
   "id": "bd311c5e1caaa1fd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:20:21.491871Z",
     "start_time": "2025-03-22T18:20:21.276451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = data_retriever.get_data('BTC')\n",
    "df['unix_time'] = pd.to_datetime(df['date-time']).astype(int) / 10**9\n",
    "\n",
    "cols_to_keep = [\n",
    "    'unix_time',\n",
    "    'liquidityRate_avg',\n",
    "    'variableBorrowRate_avg',\n",
    "    'utilizationRate_avg',\n",
    "    'close_price',\n",
    "    'volume',\n",
    "]\n",
    "\n",
    "crypto_df = df[cols_to_keep]\n",
    "crypto_df.head()"
   ],
   "id": "4dd14380c8a81907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      unix_time  liquidityRate_avg  variableBorrowRate_avg  \\\n",
       "0  1.678752e+09           0.001406                0.020714   \n",
       "1  1.678756e+09           0.000307                0.004456   \n",
       "2  1.678759e+09           0.001008                0.014002   \n",
       "3  1.678763e+09           0.000449                0.006580   \n",
       "4  1.678766e+09           0.008074                0.010621   \n",
       "\n",
       "   utilizationRate_avg  close_price       volume  \n",
       "0             0.084537     24275.71  1411.668208  \n",
       "1             0.084932     24481.00  1280.805261  \n",
       "2             0.089931     24380.52  1395.633094  \n",
       "3             0.078096     24518.10  1179.926761  \n",
       "4             0.070017     24575.21  1262.628515  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix_time</th>\n",
       "      <th>liquidityRate_avg</th>\n",
       "      <th>variableBorrowRate_avg</th>\n",
       "      <th>utilizationRate_avg</th>\n",
       "      <th>close_price</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.678752e+09</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.084537</td>\n",
       "      <td>24275.71</td>\n",
       "      <td>1411.668208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.678756e+09</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>24481.00</td>\n",
       "      <td>1280.805261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.678759e+09</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.089931</td>\n",
       "      <td>24380.52</td>\n",
       "      <td>1395.633094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.678763e+09</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.078096</td>\n",
       "      <td>24518.10</td>\n",
       "      <td>1179.926761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.678766e+09</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.070017</td>\n",
       "      <td>24575.21</td>\n",
       "      <td>1262.628515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:22:54.332210Z",
     "start_time": "2025-03-22T18:22:54.313166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = (crypto_df['variableBorrowRate_avg'] == 0).sum()\n",
    "count"
   ],
   "id": "69e1c0272c715cdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(405)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:21:48.555772Z",
     "start_time": "2025-03-22T18:21:48.543417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = (crypto_df['liquidityRate_avg'] == 0).sum()\n",
    "count"
   ],
   "id": "f941b0118f349e9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(405)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataloader",
   "id": "56e04f6711da3368"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:05.195800Z",
     "start_time": "2025-03-21T16:42:05.185010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, window_size: int, target_columns, forecast_size: int = 1):\n",
    "        self.window_size = window_size\n",
    "        self.forecast_size = forecast_size\n",
    "        self.target_columns = target_columns  \n",
    "        \n",
    "        data_array = data.values\n",
    "    \n",
    "        target_indices = [data.columns.get_loc(col) for col in target_columns]  \n",
    "\n",
    "        self.X, self.y = [], []\n",
    "        for i in range(len(data_array) - window_size - forecast_size + 1):\n",
    "            self.X.append(data_array[i : i + window_size])\n",
    "            \n",
    "            if len(target_indices) == 1:\n",
    "                self.y.append(data_array[i + window_size : i + window_size + forecast_size, target_indices[0]].reshape(-1, 1))\n",
    "            else:\n",
    "                self.y.append(data_array[i + window_size : i + window_size + forecast_size, target_indices])\n",
    "\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.X[idx], dtype=torch.float32), \n",
    "                torch.tensor(self.y[idx], dtype=torch.float32))"
   ],
   "id": "a76bed50397e338",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:05.713783Z",
     "start_time": "2025-03-21T16:42:05.702768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloaders(\n",
    "        data, \n",
    "        target_columns,\n",
    "        window_size=168,\n",
    "        forecast_size=1,\n",
    "        batch_size=32, \n",
    "        val_size=0.1,\n",
    "        test_size=0.1):\n",
    "    total_size = len(data)\n",
    "    train_size = int((1 - val_size - test_size) * total_size)\n",
    "    val_size = int(val_size * total_size)\n",
    "    \n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:train_size + val_size]\n",
    "    test_data = data[train_size + val_size:]\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(train_data, window_size, target_columns, forecast_size)\n",
    "    val_dataset = TimeSeriesDataset(val_data, window_size, target_columns, forecast_size)\n",
    "    test_dataset = TimeSeriesDataset(test_data, window_size, target_columns, forecast_size)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ],
   "id": "8b28f10830f5cb37",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "724b3cf2850f5e55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:06.612352Z",
     "start_time": "2025-03-21T16:42:06.600059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size=2, forecast_size=1, dropout=0.2):\n",
    "        super(LSTMForecaster, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.forecast_size = forecast_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :] \n",
    "        \n",
    "        forecast = []\n",
    "        for _ in range(self.forecast_size):\n",
    "            out = self.fc(out)\n",
    "            forecast.append(out.unsqueeze(1))\n",
    "        \n",
    "        forecast = torch.cat(forecast, dim=1) \n",
    "        return forecast"
   ],
   "id": "71e6229e8f3f52ad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trainer",
   "id": "87e93ebb380ec9e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:07.815516Z",
     "start_time": "2025-03-21T16:42:07.802167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.001, device=\"cuda\", patience=10, lr_patience=5, lr_decay_factor=0.1):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_decay_factor, patience=lr_patience, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement_es = 0\n",
    "    epochs_without_improvement_lr = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "                y_pred = model(X_val)\n",
    "                loss = criterion(y_pred, y_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.8f}, Val Loss: {val_loss:.8f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement_es = 0\n",
    "            epochs_without_improvement_lr = 0\n",
    "        else:\n",
    "            epochs_without_improvement_es += 1\n",
    "            epochs_without_improvement_lr += 1\n",
    "\n",
    "        if epochs_without_improvement_es >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "        if epochs_without_improvement_lr >= lr_patience:\n",
    "            print(f\"Validation loss plateaued for {lr_patience} epochs. Reducing learning rate by factor of {lr_decay_factor}.\")\n",
    "            scheduler.step(val_loss)\n",
    "            epochs_without_improvement_lr = 0"
   ],
   "id": "2e7d6c36baad6bc0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluator",
   "id": "e65b05a647451440"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:09.005235Z",
     "start_time": "2025-03-21T16:42:08.993466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_loader, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    total_samples = 0\n",
    "    total_mape = torch.zeros(model.output_size, device=device) \n",
    "    total_mse = torch.zeros(model.output_size, device=device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "            y_pred = model(X_test)\n",
    "\n",
    "            mse_per_element = criterion(y_pred, y_test)\n",
    "            mape_per_output = torch.mean(torch.abs((y_test - y_pred) / (y_test + 1e-8)), dim=(0, 1)) * 100\n",
    "\n",
    "            total_mape += mape_per_output * X_test.size(0)\n",
    "            total_samples += X_test.size(0)\n",
    "\n",
    "            mse_per_output = mse_per_element.mean(dim=(0, 1)) \n",
    "            total_mse += mse_per_output * X_test.size(0)\n",
    "\n",
    "    average_mse = total_mse.cpu().numpy() / total_samples\n",
    "    average_mape = total_mape.cpu().numpy() / total_samples\n",
    "\n",
    "    print(f\"Test MSE (for each output dimension): {average_mse}\")\n",
    "    print(f\"Test MAPE (for each output dimension): {average_mape}\")\n",
    "\n",
    "    return average_mse, average_mape\n"
   ],
   "id": "bc2bb25c5f6e902d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d77b10f1f990d624"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "4a4de125add9bae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:42:12.103165Z",
     "start_time": "2025-03-21T16:42:12.025278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_evaluate(\n",
    "        crypto_df,\n",
    "        input_size=6, \n",
    "        hidden_size=32, \n",
    "        num_layers=4, \n",
    "        output_size=2, \n",
    "        forecast_size=1, \n",
    "        dropout=0.2,\n",
    "        target_columns=['liquidityRate_avg', 'variableBorrowRate_avg'],\n",
    "        window_size=168,\n",
    "        batch_size=32,\n",
    "        val_size=0.1,\n",
    "        test_size=0.1,\n",
    "        num_epochs=100,\n",
    "        learning_rate=0.001,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        patience=10,\n",
    "        lr_patience=5,\n",
    "        lr_decay_factor=0.1,\n",
    "):\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        crypto_df,\n",
    "        target_columns=target_columns,\n",
    "        window_size=window_size,\n",
    "        forecast_size=forecast_size,\n",
    "        batch_size=batch_size,\n",
    "        val_size=val_size,\n",
    "        test_size=test_size\n",
    "    )\n",
    "    \n",
    "    model = LSTMForecaster(\n",
    "        input_size, \n",
    "        hidden_size, \n",
    "        num_layers, \n",
    "        output_size, \n",
    "        forecast_size, \n",
    "        dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        num_epochs=num_epochs, \n",
    "        learning_rate=learning_rate, \n",
    "        device=device, \n",
    "        patience=patience, \n",
    "        lr_patience=lr_patience, \n",
    "        lr_decay_factor=lr_decay_factor\n",
    "    )\n",
    "\n",
    "    evaluate_model(model, test_loader, device=device)"
   ],
   "id": "428c9d057efc70cc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:43:02.319847Z",
     "start_time": "2025-03-21T16:42:13.442148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 day\n",
    "train_and_evaluate(crypto_df, window_size=24)"
   ],
   "id": "b94f35141283a091",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00089005, Val Loss: 0.00005108\n",
      "Epoch 2/100, Train Loss: 0.00087831, Val Loss: 0.00002109\n",
      "Epoch 3/100, Train Loss: 0.00087684, Val Loss: 0.00001529\n",
      "Epoch 4/100, Train Loss: 0.00087583, Val Loss: 0.00001346\n",
      "Epoch 5/100, Train Loss: 0.00087528, Val Loss: 0.00000968\n",
      "Epoch 6/100, Train Loss: 0.00087524, Val Loss: 0.00001869\n",
      "Epoch 7/100, Train Loss: 0.00087545, Val Loss: 0.00001222\n",
      "Epoch 8/100, Train Loss: 0.00087462, Val Loss: 0.00003888\n",
      "Epoch 9/100, Train Loss: 0.00087454, Val Loss: 0.00001693\n",
      "Epoch 10/100, Train Loss: 0.00087450, Val Loss: 0.00001741\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 11/100, Train Loss: 0.00087453, Val Loss: 0.00002283\n",
      "Epoch 12/100, Train Loss: 0.00087404, Val Loss: 0.00001227\n",
      "Epoch 13/100, Train Loss: 0.00087364, Val Loss: 0.00001749\n",
      "Epoch 14/100, Train Loss: 0.00087427, Val Loss: 0.00002354\n",
      "Epoch 15/100, Train Loss: 0.00087381, Val Loss: 0.00001612\n",
      "Early stopping at epoch 15 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [3.0880735e-06 4.7451394e-05]\n",
      "Test MAPE (for each output dimension): [ 45958.246 251361.88 ]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:44:13.793414Z",
     "start_time": "2025-03-21T16:43:18.507301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 week\n",
    "train_and_evaluate(crypto_df, window_size=7*24)"
   ],
   "id": "2afa4048f8e4b9d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00111211, Val Loss: 0.00000740\n",
      "Epoch 2/100, Train Loss: 0.00090013, Val Loss: 0.00001201\n",
      "Epoch 3/100, Train Loss: 0.00089510, Val Loss: 0.00000953\n",
      "Epoch 4/100, Train Loss: 0.00088929, Val Loss: 0.00003817\n",
      "Epoch 5/100, Train Loss: 0.00088947, Val Loss: 0.00001121\n",
      "Epoch 6/100, Train Loss: 0.00088827, Val Loss: 0.00001292\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 7/100, Train Loss: 0.00088939, Val Loss: 0.00001826\n",
      "Epoch 8/100, Train Loss: 0.00088689, Val Loss: 0.00001570\n",
      "Epoch 9/100, Train Loss: 0.00088669, Val Loss: 0.00000736\n",
      "Epoch 10/100, Train Loss: 0.00088636, Val Loss: 0.00001431\n",
      "Epoch 11/100, Train Loss: 0.00088571, Val Loss: 0.00001376\n",
      "Epoch 12/100, Train Loss: 0.00088646, Val Loss: 0.00001740\n",
      "Epoch 13/100, Train Loss: 0.00088584, Val Loss: 0.00001048\n",
      "Epoch 14/100, Train Loss: 0.00088572, Val Loss: 0.00002362\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 15/100, Train Loss: 0.00088578, Val Loss: 0.00002652\n",
      "Epoch 16/100, Train Loss: 0.00088549, Val Loss: 0.00001770\n",
      "Epoch 17/100, Train Loss: 0.00088458, Val Loss: 0.00002191\n",
      "Epoch 18/100, Train Loss: 0.00088482, Val Loss: 0.00002742\n",
      "Epoch 19/100, Train Loss: 0.00088512, Val Loss: 0.00002417\n",
      "Early stopping at epoch 19 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [1.5419121e-06 6.7835390e-05]\n",
      "Test MAPE (for each output dimension): [ 8958.367 77692.08 ]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:46:07.725404Z",
     "start_time": "2025-03-21T16:44:17.997738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 month\n",
    "train_and_evaluate(crypto_df, window_size=30*24)"
   ],
   "id": "cb81f507cd524a43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00094484, Val Loss: 0.00079821\n",
      "Epoch 2/100, Train Loss: 0.00093253, Val Loss: 0.00001340\n",
      "Epoch 3/100, Train Loss: 0.00092252, Val Loss: 0.00001598\n",
      "Epoch 4/100, Train Loss: 0.00092306, Val Loss: 0.00002874\n",
      "Epoch 5/100, Train Loss: 0.00092159, Val Loss: 0.00002014\n",
      "Epoch 6/100, Train Loss: 0.00092160, Val Loss: 0.00002715\n",
      "Epoch 7/100, Train Loss: 0.00092134, Val Loss: 0.00002522\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 8/100, Train Loss: 0.00092050, Val Loss: 0.00001220\n",
      "Epoch 9/100, Train Loss: 0.00091991, Val Loss: 0.00001533\n",
      "Epoch 10/100, Train Loss: 0.00091983, Val Loss: 0.00001069\n",
      "Epoch 11/100, Train Loss: 0.00092160, Val Loss: 0.00001771\n",
      "Epoch 12/100, Train Loss: 0.00091888, Val Loss: 0.00001728\n",
      "Epoch 13/100, Train Loss: 0.00091947, Val Loss: 0.00001716\n",
      "Epoch 14/100, Train Loss: 0.00091874, Val Loss: 0.00001188\n",
      "Epoch 15/100, Train Loss: 0.00091877, Val Loss: 0.00002148\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 16/100, Train Loss: 0.00091836, Val Loss: 0.00002419\n",
      "Epoch 17/100, Train Loss: 0.00091717, Val Loss: 0.00008193\n",
      "Epoch 18/100, Train Loss: 0.00091879, Val Loss: 0.00002255\n",
      "Epoch 19/100, Train Loss: 0.00091785, Val Loss: 0.00002030\n",
      "Epoch 20/100, Train Loss: 0.00091773, Val Loss: 0.00001717\n",
      "Early stopping at epoch 20 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [4.5435891e-06 4.4367207e-05]\n",
      "Test MAPE (for each output dimension): [1137.9398   191.15257]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb9cd3336100d674"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
