{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:11.645647Z",
     "start_time": "2025-03-21T16:47:08.641887Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:11.663108Z",
     "start_time": "2025-03-21T16:47:11.650645Z"
    }
   },
   "cell_type": "code",
   "source": "import data.data_retriever as data_retriever",
   "id": "5dcf505a2204266c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:11.872186Z",
     "start_time": "2025-03-21T16:47:11.860080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(0)"
   ],
   "id": "bd311c5e1caaa1fd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:13.575891Z",
     "start_time": "2025-03-21T16:47:13.381639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = data_retriever.get_data('USDC')\n",
    "df['unix_time'] = pd.to_datetime(df['date-time']).astype(int) / 10**9\n",
    "\n",
    "cols_to_keep = [\n",
    "    'unix_time',\n",
    "    'liquidityRate_avg',\n",
    "    'variableBorrowRate_avg',\n",
    "    'utilizationRate_avg',\n",
    "    'close_price',\n",
    "    'volume',\n",
    "]\n",
    "\n",
    "crypto_df = df[cols_to_keep]\n",
    "crypto_df.head()"
   ],
   "id": "4dd14380c8a81907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      unix_time  liquidityRate_avg  variableBorrowRate_avg  \\\n",
       "0  1.678752e+09           0.005627                0.014052   \n",
       "1  1.678756e+09           0.008435                0.020909   \n",
       "2  1.678759e+09           0.009119                0.022602   \n",
       "3  1.678763e+09           0.007338                0.017976   \n",
       "4  1.678766e+09           0.006334                0.014046   \n",
       "\n",
       "   utilizationRate_avg  close_price        volume  \n",
       "0             0.444227       0.9990  1.218521e+06  \n",
       "1             0.447503       0.9991  1.459872e+06  \n",
       "2             0.447697       0.9992  2.188143e+06  \n",
       "3             0.453755       0.9993  2.800380e+06  \n",
       "4             0.464677       0.9994  1.048281e+06  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix_time</th>\n",
       "      <th>liquidityRate_avg</th>\n",
       "      <th>variableBorrowRate_avg</th>\n",
       "      <th>utilizationRate_avg</th>\n",
       "      <th>close_price</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.678752e+09</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>0.444227</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>1.218521e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.678756e+09</td>\n",
       "      <td>0.008435</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>0.447503</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>1.459872e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.678759e+09</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>0.447697</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>2.188143e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.678763e+09</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>0.453755</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>2.800380e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.678766e+09</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.464677</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.048281e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataloader",
   "id": "56e04f6711da3368"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:16.325286Z",
     "start_time": "2025-03-21T16:47:16.315242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, window_size: int, target_columns, forecast_size: int = 1):\n",
    "        self.window_size = window_size\n",
    "        self.forecast_size = forecast_size\n",
    "        self.target_columns = target_columns  \n",
    "        \n",
    "        data_array = data.values\n",
    "    \n",
    "        target_indices = [data.columns.get_loc(col) for col in target_columns]  \n",
    "\n",
    "        self.X, self.y = [], []\n",
    "        for i in range(len(data_array) - window_size - forecast_size + 1):\n",
    "            self.X.append(data_array[i : i + window_size])\n",
    "            \n",
    "            if len(target_indices) == 1:\n",
    "                self.y.append(data_array[i + window_size : i + window_size + forecast_size, target_indices[0]].reshape(-1, 1))\n",
    "            else:\n",
    "                self.y.append(data_array[i + window_size : i + window_size + forecast_size, target_indices])\n",
    "\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.X[idx], dtype=torch.float32), \n",
    "                torch.tensor(self.y[idx], dtype=torch.float32))"
   ],
   "id": "a76bed50397e338",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:17.097762Z",
     "start_time": "2025-03-21T16:47:17.084475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloaders(\n",
    "        data, \n",
    "        target_columns,\n",
    "        window_size=168,\n",
    "        forecast_size=1,\n",
    "        batch_size=32, \n",
    "        val_size=0.1,\n",
    "        test_size=0.1):\n",
    "    total_size = len(data)\n",
    "    train_size = int((1 - val_size - test_size) * total_size)\n",
    "    val_size = int(val_size * total_size)\n",
    "    \n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:train_size + val_size]\n",
    "    test_data = data[train_size + val_size:]\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(train_data, window_size, target_columns, forecast_size)\n",
    "    val_dataset = TimeSeriesDataset(val_data, window_size, target_columns, forecast_size)\n",
    "    test_dataset = TimeSeriesDataset(test_data, window_size, target_columns, forecast_size)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ],
   "id": "8b28f10830f5cb37",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "724b3cf2850f5e55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:18.603424Z",
     "start_time": "2025-03-21T16:47:18.586369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size=2, forecast_size=1, dropout=0.2):\n",
    "        super(LSTMForecaster, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.forecast_size = forecast_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :] \n",
    "        \n",
    "        forecast = []\n",
    "        for _ in range(self.forecast_size):\n",
    "            out = self.fc(out)\n",
    "            forecast.append(out.unsqueeze(1))\n",
    "        \n",
    "        forecast = torch.cat(forecast, dim=1) \n",
    "        return forecast"
   ],
   "id": "71e6229e8f3f52ad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trainer",
   "id": "87e93ebb380ec9e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:20.068072Z",
     "start_time": "2025-03-21T16:47:20.053168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.001, device=\"cuda\", patience=10, lr_patience=5, lr_decay_factor=0.1):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_decay_factor, patience=lr_patience, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement_es = 0\n",
    "    epochs_without_improvement_lr = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "                y_pred = model(X_val)\n",
    "                loss = criterion(y_pred, y_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.8f}, Val Loss: {val_loss:.8f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement_es = 0\n",
    "            epochs_without_improvement_lr = 0\n",
    "        else:\n",
    "            epochs_without_improvement_es += 1\n",
    "            epochs_without_improvement_lr += 1\n",
    "\n",
    "        if epochs_without_improvement_es >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "        if epochs_without_improvement_lr >= lr_patience:\n",
    "            print(f\"Validation loss plateaued for {lr_patience} epochs. Reducing learning rate by factor of {lr_decay_factor}.\")\n",
    "            scheduler.step(val_loss)\n",
    "            epochs_without_improvement_lr = 0"
   ],
   "id": "2e7d6c36baad6bc0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluator",
   "id": "e65b05a647451440"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:21.880768Z",
     "start_time": "2025-03-21T16:47:21.871541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_loader, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    total_samples = 0\n",
    "    total_mape = torch.zeros(model.output_size, device=device) \n",
    "    total_mse = torch.zeros(model.output_size, device=device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "            y_pred = model(X_test)\n",
    "\n",
    "            mse_per_element = criterion(y_pred, y_test)\n",
    "            mape_per_output = torch.mean(torch.abs((y_test - y_pred) / (y_test + 1e-8)), dim=(0, 1)) * 100\n",
    "\n",
    "            total_mape += mape_per_output * X_test.size(0)\n",
    "            total_samples += X_test.size(0)\n",
    "\n",
    "            mse_per_output = mse_per_element.mean(dim=(0, 1)) \n",
    "            total_mse += mse_per_output * X_test.size(0)\n",
    "\n",
    "    average_mse = total_mse.cpu().numpy() / total_samples\n",
    "    average_mape = total_mape.cpu().numpy() / total_samples\n",
    "\n",
    "    print(f\"Test MSE (for each output dimension): {average_mse}\")\n",
    "    print(f\"Test MAPE (for each output dimension): {average_mape}\")\n",
    "\n",
    "    return average_mse, average_mape\n"
   ],
   "id": "bc2bb25c5f6e902d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d77b10f1f990d624"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "4a4de125add9bae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:47:24.455552Z",
     "start_time": "2025-03-21T16:47:24.415721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_evaluate(\n",
    "        crypto_df,\n",
    "        input_size=6, \n",
    "        hidden_size=32, \n",
    "        num_layers=4, \n",
    "        output_size=2, \n",
    "        forecast_size=1, \n",
    "        dropout=0.2,\n",
    "        target_columns=['liquidityRate_avg', 'variableBorrowRate_avg'],\n",
    "        window_size=168,\n",
    "        batch_size=32,\n",
    "        val_size=0.1,\n",
    "        test_size=0.1,\n",
    "        num_epochs=100,\n",
    "        learning_rate=0.001,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        patience=10,\n",
    "        lr_patience=5,\n",
    "        lr_decay_factor=0.1,\n",
    "):\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        crypto_df,\n",
    "        target_columns=target_columns,\n",
    "        window_size=window_size,\n",
    "        forecast_size=forecast_size,\n",
    "        batch_size=batch_size,\n",
    "        val_size=val_size,\n",
    "        test_size=test_size\n",
    "    )\n",
    "    \n",
    "    model = LSTMForecaster(\n",
    "        input_size, \n",
    "        hidden_size, \n",
    "        num_layers, \n",
    "        output_size, \n",
    "        forecast_size, \n",
    "        dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        num_epochs=num_epochs, \n",
    "        learning_rate=learning_rate, \n",
    "        device=device, \n",
    "        patience=patience, \n",
    "        lr_patience=lr_patience, \n",
    "        lr_decay_factor=lr_decay_factor\n",
    "    )\n",
    "\n",
    "    evaluate_model(model, test_loader, device=device)"
   ],
   "id": "428c9d057efc70cc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:48:14.360676Z",
     "start_time": "2025-03-21T16:47:25.909676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 day\n",
    "train_and_evaluate(crypto_df, window_size=24)"
   ],
   "id": "b94f35141283a091",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00133152, Val Loss: 0.00271658\n",
      "Epoch 2/100, Train Loss: 0.00128902, Val Loss: 0.00286419\n",
      "Epoch 3/100, Train Loss: 0.00127949, Val Loss: 0.00294469\n",
      "Epoch 4/100, Train Loss: 0.00128006, Val Loss: 0.00272830\n",
      "Epoch 5/100, Train Loss: 0.00127436, Val Loss: 0.00259581\n",
      "Epoch 6/100, Train Loss: 0.00128120, Val Loss: 0.00289617\n",
      "Epoch 7/100, Train Loss: 0.00127758, Val Loss: 0.00312897\n",
      "Epoch 8/100, Train Loss: 0.00127447, Val Loss: 0.00286827\n",
      "Epoch 9/100, Train Loss: 0.00127553, Val Loss: 0.00271369\n",
      "Epoch 10/100, Train Loss: 0.00127802, Val Loss: 0.00275847\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 11/100, Train Loss: 0.00127334, Val Loss: 0.00282537\n",
      "Epoch 12/100, Train Loss: 0.00127617, Val Loss: 0.00288639\n",
      "Epoch 13/100, Train Loss: 0.00127133, Val Loss: 0.00286591\n",
      "Epoch 14/100, Train Loss: 0.00127263, Val Loss: 0.00289460\n",
      "Epoch 15/100, Train Loss: 0.00127172, Val Loss: 0.00289496\n",
      "Early stopping at epoch 15 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [0.00070969 0.0011894 ]\n",
      "Test MAPE (for each output dimension): [31.716581 26.880995]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:49:15.724344Z",
     "start_time": "2025-03-21T16:48:25.842009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 week\n",
    "train_and_evaluate(crypto_df, window_size=7*24)"
   ],
   "id": "2afa4048f8e4b9d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00138886, Val Loss: 0.00333181\n",
      "Epoch 2/100, Train Loss: 0.00128356, Val Loss: 0.00316129\n",
      "Epoch 3/100, Train Loss: 0.00127711, Val Loss: 0.00290112\n",
      "Epoch 4/100, Train Loss: 0.00128248, Val Loss: 0.00300550\n",
      "Epoch 5/100, Train Loss: 0.00127263, Val Loss: 0.00303386\n",
      "Epoch 6/100, Train Loss: 0.00128477, Val Loss: 0.00302591\n",
      "Epoch 7/100, Train Loss: 0.00127840, Val Loss: 0.00280287\n",
      "Epoch 8/100, Train Loss: 0.00127131, Val Loss: 0.00302498\n",
      "Epoch 9/100, Train Loss: 0.00127337, Val Loss: 0.00288837\n",
      "Epoch 10/100, Train Loss: 0.00127188, Val Loss: 0.00293777\n",
      "Epoch 11/100, Train Loss: 0.00127051, Val Loss: 0.00323483\n",
      "Epoch 12/100, Train Loss: 0.00127262, Val Loss: 0.00321931\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 13/100, Train Loss: 0.00127583, Val Loss: 0.00300165\n",
      "Epoch 14/100, Train Loss: 0.00127103, Val Loss: 0.00321328\n",
      "Epoch 15/100, Train Loss: 0.00127460, Val Loss: 0.00304872\n",
      "Epoch 16/100, Train Loss: 0.00126791, Val Loss: 0.00296301\n",
      "Epoch 17/100, Train Loss: 0.00127171, Val Loss: 0.00312856\n",
      "Early stopping at epoch 17 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [0.00053737 0.00096689]\n",
      "Test MAPE (for each output dimension): [30.064936 25.046225]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:51:02.440143Z",
     "start_time": "2025-03-21T16:49:23.982810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# window size of 1 month\n",
    "train_and_evaluate(crypto_df, window_size=30*24)"
   ],
   "id": "cb81f507cd524a43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siam\\anaconda3\\envs\\aave\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.00147058, Val Loss: 0.00359548\n",
      "Epoch 2/100, Train Loss: 0.00128096, Val Loss: 0.00408505\n",
      "Epoch 3/100, Train Loss: 0.00127770, Val Loss: 0.00388415\n",
      "Epoch 4/100, Train Loss: 0.00127662, Val Loss: 0.00405944\n",
      "Epoch 5/100, Train Loss: 0.00127861, Val Loss: 0.00466426\n",
      "Epoch 6/100, Train Loss: 0.00127905, Val Loss: 0.00397106\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 7/100, Train Loss: 0.00127543, Val Loss: 0.00421714\n",
      "Epoch 8/100, Train Loss: 0.00127287, Val Loss: 0.00357628\n",
      "Epoch 9/100, Train Loss: 0.00127536, Val Loss: 0.00433844\n",
      "Epoch 10/100, Train Loss: 0.00127424, Val Loss: 0.00428045\n",
      "Epoch 11/100, Train Loss: 0.00127378, Val Loss: 0.00422194\n",
      "Epoch 12/100, Train Loss: 0.00127290, Val Loss: 0.00406339\n",
      "Epoch 13/100, Train Loss: 0.00127487, Val Loss: 0.00381324\n",
      "Validation loss plateaued for 5 epochs. Reducing learning rate by factor of 0.1.\n",
      "Epoch 14/100, Train Loss: 0.00127367, Val Loss: 0.00391980\n",
      "Epoch 15/100, Train Loss: 0.00127116, Val Loss: 0.00406876\n",
      "Epoch 16/100, Train Loss: 0.00127449, Val Loss: 0.00424711\n",
      "Epoch 17/100, Train Loss: 0.00127113, Val Loss: 0.00388302\n",
      "Epoch 18/100, Train Loss: 0.00127254, Val Loss: 0.00397340\n",
      "Early stopping at epoch 18 due to no improvement in validation loss for 10 epochs.\n",
      "Test MSE (for each output dimension): [0.00016031 0.00024304]\n",
      "Test MAPE (for each output dimension): [28.173067 15.429122]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb9cd3336100d674"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
